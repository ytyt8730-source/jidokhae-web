#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Smart Context Packer for LLM
============================

í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ LLMì—ê²Œ íš¨ìœ¨ì ìœ¼ë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•œ ì§€ëŠ¥í˜• íŒ¨í‚¹ ìŠ¤í¬ë¦½íŠ¸.

ì‚¬ìš©ë²•:
    python pack_context.py                    # ì „ì²´ í”„ë¡œì íŠ¸
    python pack_context.py --target src/lib   # íŠ¹ì • í´ë”ë§Œ
    python pack_context.py --target core,docs # ì—¬ëŸ¬ í´ë”
    python pack_context.py --no-minify        # ì••ì¶• ì—†ì´
    python pack_context.py --max-tokens 50000 # í† í° ì œí•œ

Author: Claude Code
Version: 1.0.0
"""

import os
import re
import sys
import argparse
import io

# Windows ì½˜ì†” UTF-8 ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
from pathlib import Path
from typing import List, Set, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime

# í´ë¦½ë³´ë“œ ë³µì‚¬ë¥¼ ìœ„í•œ ì„ íƒì  import
try:
    import pyperclip
    HAS_CLIPBOARD = True
except ImportError:
    HAS_CLIPBOARD = False


@dataclass
class PackerConfig:
    """íŒ¨ì»¤ ì„¤ì •"""
    # í•­ìƒ ì œì™¸í•  ë””ë ‰í† ë¦¬
    exclude_dirs: Set[str] = field(default_factory=lambda: {
        '.git', 'node_modules', 'build', 'dist', '__pycache__',
        '.next', '.vercel', '.turbo', 'coverage', '.nyc_output',
        'venv', '.venv', 'env', '.env', '.idea', '.vscode',
    })

    # í•­ìƒ ì œì™¸í•  íŒŒì¼
    exclude_files: Set[str] = field(default_factory=lambda: {
        'package-lock.json', 'yarn.lock', 'pnpm-lock.yaml',
        '.DS_Store', 'Thumbs.db', '.gitignore',
    })

    # ì œì™¸í•  í™•ì¥ì
    exclude_extensions: Set[str] = field(default_factory=lambda: {
        '.png', '.jpg', '.jpeg', '.gif', '.ico', '.svg', '.webp',
        '.mp4', '.mp3', '.wav', '.avi', '.mov',
        '.pdf', '.doc', '.docx', '.xls', '.xlsx',
        '.zip', '.tar', '.gz', '.rar', '.7z',
        '.exe', '.dll', '.so', '.dylib',
        '.pyc', '.pyo', '.class', '.o',
        '.woff', '.woff2', '.ttf', '.eot', '.otf',
    })

    # ìµœìš°ì„  í¬í•¨ íŒŒì¼/í´ë” (í•­ìƒ í¬í•¨)
    priority_paths: Set[str] = field(default_factory=lambda: {
        '.cursorrules', 'CLAUDE.md', 'roadmap',
        'log/current-state.md', 'core',
    })

    # ì¤‘ìš” íŒŒì¼ íŒ¨í„´ (ìš°ì„  ì •ë ¬)
    important_patterns: List[str] = field(default_factory=lambda: [
        r'\.cursorrules$',
        r'CLAUDE\.md$',
        r'current-state\.md$',
        r'milestones\.md$',
        r'PRD\.md$',
        r'package\.json$',
        r'tsconfig\.json$',
        r'tailwind\.config\.',
    ])

    # ìµœëŒ€ íŒŒì¼ í¬ê¸° (bytes)
    max_file_size: int = 100_000  # 100KB

    # í† í° ì¶”ì • (ë‹¨ì–´ë‹¹ í‰ê·  í† í°)
    tokens_per_word: float = 1.3
    tokens_per_char: float = 0.25


class TokenEstimator:
    """í† í° ìˆ˜ ì¶”ì •ê¸°"""

    def __init__(self, config: PackerConfig):
        self.config = config

    def estimate(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ì¶”ì •"""
        # ë°©ë²• 1: ë‹¨ì–´ ê¸°ë°˜
        words = len(text.split())
        word_tokens = int(words * self.config.tokens_per_word)

        # ë°©ë²• 2: ë¬¸ì ê¸°ë°˜
        char_tokens = int(len(text) * self.config.tokens_per_char)

        # ë‘ ë°©ë²•ì˜ í‰ê· 
        return (word_tokens + char_tokens) // 2

    def format_tokens(self, tokens: int) -> str:
        """í† í° ìˆ˜ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·"""
        if tokens >= 1_000_000:
            return f"{tokens / 1_000_000:.1f}M"
        elif tokens >= 1_000:
            return f"{tokens / 1_000:.1f}K"
        return str(tokens)


class ContentMinifier:
    """ì½”ë“œ ì••ì¶•ê¸°"""

    def __init__(self, enabled: bool = True):
        self.enabled = enabled

    def minify(self, content: str, file_ext: str) -> str:
        """ì½”ë“œ ì••ì¶• (ë¹ˆ ì¤„ ì œê±°, ê°„ë‹¨í•œ ì •ë¦¬)"""
        if not self.enabled:
            return content

        # íŒŒì¼ì´ ë„ˆë¬´ í¬ë©´ ì •ê·œì‹ ê±´ë„ˆë›°ê¸° (ì„±ëŠ¥ ìµœì í™”)
        if len(content) > 50000:
            content = content.strip()
            return content

        # ì—°ì†ëœ ë¹ˆ ì¤„ì„ í•˜ë‚˜ë¡œ (ê°„ë‹¨í•œ íŒ¨í„´ë§Œ)
        content = re.sub(r'\n{3,}', '\n\n', content)

        # íŒŒì¼ ì‹œì‘/ëì˜ ë¹ˆ ì¤„ ì œê±°
        content = content.strip()

        return content


class FileFilter:
    """íŒŒì¼ í•„í„°ë§"""

    def __init__(self, config: PackerConfig):
        self.config = config

    def should_exclude_dir(self, dir_name: str) -> bool:
        """ë””ë ‰í† ë¦¬ ì œì™¸ ì—¬ë¶€"""
        return dir_name in self.config.exclude_dirs or dir_name.startswith('.')

    def should_exclude_file(self, file_path: Path) -> bool:
        """íŒŒì¼ ì œì™¸ ì—¬ë¶€"""
        # íŒŒì¼ëª…ìœ¼ë¡œ ì œì™¸
        if file_path.name in self.config.exclude_files:
            return True

        # í™•ì¥ìë¡œ ì œì™¸
        if file_path.suffix.lower() in self.config.exclude_extensions:
            return True

        # íŒŒì¼ í¬ê¸°ë¡œ ì œì™¸
        try:
            if file_path.stat().st_size > self.config.max_file_size:
                return True
        except OSError:
            return True

        return False

    def is_priority_path(self, rel_path: str) -> bool:
        """ìš°ì„  í¬í•¨ ê²½ë¡œì¸ì§€ í™•ì¸"""
        rel_path_lower = rel_path.lower().replace('\\', '/')
        for priority in self.config.priority_paths:
            if rel_path_lower == priority.lower() or rel_path_lower.startswith(priority.lower() + '/'):
                return True
        return False

    def get_priority_score(self, rel_path: str) -> int:
        """íŒŒì¼ì˜ ìš°ì„ ìˆœìœ„ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ë¨¼ì €)"""
        # ì¤‘ìš” íŒ¨í„´ ë§¤ì¹­
        for i, pattern in enumerate(self.config.important_patterns):
            if re.search(pattern, rel_path, re.IGNORECASE):
                return i

        # ìš°ì„  ê²½ë¡œ
        if self.is_priority_path(rel_path):
            return 100

        # ì¼ë°˜ íŒŒì¼
        return 1000


@dataclass
class PackedFile:
    """íŒ¨í‚¹ëœ íŒŒì¼ ì •ë³´"""
    rel_path: str
    content: str
    original_size: int
    packed_size: int
    priority: int


class SmartContextPacker:
    """Smart Context Packer ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(
        self,
        root_dir: str,
        targets: Optional[List[str]] = None,
        minify: bool = True,
        max_tokens: Optional[int] = None,
        config: Optional[PackerConfig] = None,
    ):
        self.root_dir = Path(root_dir).resolve()
        self.targets = targets
        self.minify = minify
        self.max_tokens = max_tokens
        self.config = config or PackerConfig()

        self.filter = FileFilter(self.config)
        self.minifier = ContentMinifier(minify)
        self.estimator = TokenEstimator(self.config)

        self.packed_files: List[PackedFile] = []
        self.stats = {
            'total_files': 0,
            'included_files': 0,
            'excluded_files': 0,
            'original_size': 0,
            'packed_size': 0,
        }

    def discover_files(self) -> List[Path]:
        """íŒŒì¼ íƒìƒ‰"""
        files = []

        # íƒ€ê²Ÿì´ ì§€ì •ëœ ê²½ìš°
        if self.targets:
            # í•­ìƒ í¬í•¨í•  ìš°ì„  íŒŒì¼ë“¤ ë¨¼ì € ì¶”ê°€
            for priority_path in self.config.priority_paths:
                full_path = self.root_dir / priority_path
                if full_path.is_file():
                    files.append(full_path)
                elif full_path.is_dir():
                    files.extend(self._scan_directory(full_path))

            # íƒ€ê²Ÿ í´ë”ë“¤ ì¶”ê°€
            for target in self.targets:
                target_path = self.root_dir / target
                if target_path.is_file():
                    files.append(target_path)
                elif target_path.is_dir():
                    files.extend(self._scan_directory(target_path))
        else:
            # ì „ì²´ ìŠ¤ìº”
            files = self._scan_directory(self.root_dir)

        # ì¤‘ë³µ ì œê±°
        files = list(dict.fromkeys(files))

        return files

    def _scan_directory(self, directory: Path) -> List[Path]:
        """ë””ë ‰í† ë¦¬ ì¬ê·€ ìŠ¤ìº”"""
        files = []

        try:
            for item in directory.iterdir():
                if item.is_dir():
                    if not self.filter.should_exclude_dir(item.name):
                        files.extend(self._scan_directory(item))
                elif item.is_file():
                    if not self.filter.should_exclude_file(item):
                        files.append(item)
        except PermissionError:
            pass

        return files

    def pack_file(self, file_path: Path) -> Optional[PackedFile]:
        """ë‹¨ì¼ íŒŒì¼ íŒ¨í‚¹"""
        try:
            rel_path = file_path.relative_to(self.root_dir).as_posix()

            # íŒŒì¼ ì½ê¸°
            try:
                content = file_path.read_text(encoding='utf-8')
            except UnicodeDecodeError:
                # ë°”ì´ë„ˆë¦¬ íŒŒì¼ ìŠ¤í‚µ
                return None

            original_size = len(content)

            # ì••ì¶•
            packed_content = self.minifier.minify(content, file_path.suffix)
            packed_size = len(packed_content)

            # ìš°ì„ ìˆœìœ„
            priority = self.filter.get_priority_score(rel_path)

            return PackedFile(
                rel_path=rel_path,
                content=packed_content,
                original_size=original_size,
                packed_size=packed_size,
                priority=priority,
            )
        except Exception as e:
            print(f"âš ï¸  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_path} - {e}")
            return None

    def pack(self) -> str:
        """ì „ì²´ íŒ¨í‚¹ ì‹¤í–‰"""
        print("ğŸ” íŒŒì¼ íƒìƒ‰ ì¤‘...")
        files = self.discover_files()
        self.stats['total_files'] = len(files)

        total = len(files)
        print(f"ğŸ“¦ {total}ê°œ íŒŒì¼ íŒ¨í‚¹ ì¤‘...")

        # íŒŒì¼ íŒ¨í‚¹ (ì§„í–‰ ìƒí™© í‘œì‹œ)
        for i, file_path in enumerate(files):
            # 10ê°œë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ì— ì§„í–‰ ìƒí™© ì¶œë ¥
            if (i + 1) % 10 == 0 or (i + 1) == total:
                print(f"   ì§„í–‰: {i + 1}/{total} ({(i + 1) * 100 // total}%)", end='\r')

            packed = self.pack_file(file_path)
            if packed:
                self.packed_files.append(packed)
                self.stats['included_files'] += 1
                self.stats['original_size'] += packed.original_size
                self.stats['packed_size'] += packed.packed_size
            else:
                self.stats['excluded_files'] += 1

        print()  # ì¤„ë°”ê¿ˆ

        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        self.packed_files.sort(key=lambda x: x.priority)

        # XML í¬ë§·ìœ¼ë¡œ ì¡°í•©
        print("ğŸ“ ì¶œë ¥ ìƒì„± ì¤‘...")
        output = self._generate_output()

        # í† í° ì œí•œ ì ìš©
        if self.max_tokens:
            output = self._apply_token_limit(output)

        return output

    def _generate_output(self) -> str:
        """ì¶œë ¥ ìƒì„±"""
        parts = []

        # í—¤ë”
        parts.append(self._generate_header())

        # íŒŒì¼ ëª©ë¡
        parts.append("<file_list>")
        for pf in self.packed_files:
            parts.append(f"  - {pf.rel_path}")
        parts.append("</file_list>\n")

        # íŒŒì¼ ë‚´ìš©
        parts.append("<files>")
        for pf in self.packed_files:
            parts.append(f'\n<file path="{pf.rel_path}">')
            parts.append(pf.content)
            parts.append('</file>')
        parts.append("\n</files>")

        return '\n'.join(parts)

    def _generate_header(self) -> str:
        """í—¤ë” ìƒì„±"""
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # íƒ€ê²Ÿ ì •ë³´
        if self.targets:
            target_info = ", ".join(self.targets)
        else:
            target_info = "ì „ì²´ í”„ë¡œì íŠ¸"

        return f"""<context_pack>
<meta>
  <project>{self.root_dir.name}</project>
  <target>{target_info}</target>
  <generated>{now}</generated>
  <files_count>{self.stats['included_files']}</files_count>
  <minified>{"yes" if self.minify else "no"}</minified>
</meta>
"""

    def _apply_token_limit(self, output: str) -> str:
        """í† í° ì œí•œ ì ìš©"""
        current_tokens = self.estimator.estimate(output)

        if current_tokens <= self.max_tokens:
            return output

        print(f"âš ï¸  í† í° ì œí•œ ì´ˆê³¼: {self.estimator.format_tokens(current_tokens)} > {self.estimator.format_tokens(self.max_tokens)}")
        print("   ìš°ì„ ìˆœìœ„ê°€ ë‚®ì€ íŒŒì¼ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤...")

        # ë¨¼ì € ëª‡ ê°œë¥¼ ì œê±°í•´ì•¼ í•˜ëŠ”ì§€ ê³„ì‚°
        removed_count = 0
        while current_tokens > self.max_tokens and self.packed_files:
            removed = self.packed_files.pop()
            removed_count += 1
            # ì œê±°ëœ íŒŒì¼ì˜ í† í°ë§Œ ëŒ€ëµ ë¹¼ê¸° (ì¬ìƒì„± ì—†ì´)
            removed_tokens = self.estimator.estimate(removed.content) + 50  # íƒœê·¸ overhead
            current_tokens -= removed_tokens

        if removed_count > 0:
            print(f"   {removed_count}ê°œ íŒŒì¼ ì œê±°ë¨")
            # ìµœì¢… ì¶œë ¥ í•œ ë²ˆë§Œ ì¬ìƒì„±
            output = self._generate_output()

        return output

    def get_report(self, output: str) -> str:
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        tokens = self.estimator.estimate(output)

        lines = [
            "",
            "â”" * 50,
            "ğŸ“Š íŒ¨í‚¹ ê²°ê³¼",
            "â”" * 50,
            f"  ğŸ“ ì´ íƒìƒ‰ íŒŒì¼: {self.stats['total_files']}ê°œ",
            f"  âœ… í¬í•¨ëœ íŒŒì¼: {self.stats['included_files']}ê°œ",
            f"  âŒ ì œì™¸ëœ íŒŒì¼: {self.stats['excluded_files']}ê°œ",
            "",
            f"  ğŸ“ ì›ë³¸ í¬ê¸°: {self._format_size(self.stats['original_size'])}",
            f"  ğŸ“¦ íŒ¨í‚¹ í¬ê¸°: {self._format_size(self.stats['packed_size'])}",
            f"  ğŸ’¾ ì••ì¶•ë¥ : {self._calc_compression_ratio()}%",
            "",
            f"  ğŸ¯ ì¶”ì • í† í°: {self.estimator.format_tokens(tokens)} ({tokens:,})",
            "â”" * 50,
        ]

        return '\n'.join(lines)

    def _format_size(self, size: int) -> str:
        """íŒŒì¼ í¬ê¸° í¬ë§·"""
        if size >= 1_000_000:
            return f"{size / 1_000_000:.2f} MB"
        elif size >= 1_000:
            return f"{size / 1_000:.2f} KB"
        return f"{size} bytes"

    def _calc_compression_ratio(self) -> str:
        """ì••ì¶•ë¥  ê³„ì‚°"""
        if self.stats['original_size'] == 0:
            return "0"
        ratio = (1 - self.stats['packed_size'] / self.stats['original_size']) * 100
        return f"{ratio:.1f}"


def copy_to_clipboard(text: str) -> bool:
    """í´ë¦½ë³´ë“œì— ë³µì‚¬"""
    if HAS_CLIPBOARD:
        try:
            pyperclip.copy(text)
            return True
        except Exception:
            pass

    # Windows ëŒ€ì•ˆ
    if sys.platform == 'win32':
        try:
            import subprocess
            process = subprocess.Popen(
                ['clip'],
                stdin=subprocess.PIPE,
                shell=True
            )
            process.communicate(text.encode('utf-8'))
            return True
        except Exception:
            pass

    return False


def main():
    parser = argparse.ArgumentParser(
        description='Smart Context Packer - LLMì„ ìœ„í•œ ì§€ëŠ¥í˜• ì»¨í…ìŠ¤íŠ¸ íŒ¨ì»¤',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python pack_context.py                          # ì „ì²´ í”„ë¡œì íŠ¸
  python pack_context.py --target src/lib         # íŠ¹ì • í´ë”
  python pack_context.py --target "core,docs"     # ì—¬ëŸ¬ í´ë”
  python pack_context.py --no-minify              # ì••ì¶• ì—†ì´
  python pack_context.py --max-tokens 50000       # í† í° ì œí•œ
  python pack_context.py --output my_context.txt  # ì¶œë ¥ íŒŒì¼ ì§€ì •
        """
    )

    parser.add_argument(
        '--target', '-t',
        type=str,
        help='íŒ¨í‚¹í•  íŠ¹ì • í´ë”/íŒŒì¼ (ì‰¼í‘œë¡œ êµ¬ë¶„)'
    )

    parser.add_argument(
        '--root', '-r',
        type=str,
        default='.',
        help='í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ë””ë ‰í† ë¦¬)'
    )

    parser.add_argument(
        '--output', '-o',
        type=str,
        default='_CONTEXT_PACK.txt',
        help='ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸: _CONTEXT_PACK.txt)'
    )

    parser.add_argument(
        '--no-minify',
        action='store_true',
        help='ì½”ë“œ ì••ì¶• ë¹„í™œì„±í™”'
    )

    parser.add_argument(
        '--max-tokens',
        type=int,
        help='ìµœëŒ€ í† í° ìˆ˜ ì œí•œ'
    )

    parser.add_argument(
        '--no-clipboard',
        action='store_true',
        help='í´ë¦½ë³´ë“œ ë³µì‚¬ ë¹„í™œì„±í™”'
    )

    parser.add_argument(
        '--list-only',
        action='store_true',
        help='íŒŒì¼ ëª©ë¡ë§Œ ì¶œë ¥ (íŒ¨í‚¹ ì•ˆ í•¨)'
    )

    args = parser.parse_args()

    # íƒ€ê²Ÿ íŒŒì‹±
    targets = None
    if args.target:
        targets = [t.strip() for t in args.target.split(',')]

    # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²°ì •
    root_dir = Path(args.root).resolve()

    # jidokhae í´ë”ê°€ ìˆìœ¼ë©´ ìƒìœ„ì—ì„œ ì‹¤í–‰í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
    if not (root_dir / 'CLAUDE.md').exists() and (root_dir / 'jidokhae').exists():
        # ì´ë¯¸ ì˜¬ë°”ë¥¸ ìœ„ì¹˜
        pass

    print(f"ğŸš€ Smart Context Packer")
    print(f"   ë£¨íŠ¸: {root_dir}")
    if targets:
        print(f"   íƒ€ê²Ÿ: {', '.join(targets)}")
    print()

    # íŒ¨ì»¤ ìƒì„±
    packer = SmartContextPacker(
        root_dir=str(root_dir),
        targets=targets,
        minify=not args.no_minify,
        max_tokens=args.max_tokens,
    )

    # íŒŒì¼ ëª©ë¡ë§Œ ì¶œë ¥
    if args.list_only:
        files = packer.discover_files()
        print(f"ğŸ“ ë°œê²¬ëœ íŒŒì¼: {len(files)}ê°œ\n")
        for f in files:
            rel_path = f.relative_to(root_dir).as_posix()
            priority = packer.filter.get_priority_score(rel_path)
            marker = "â­" if priority < 100 else "  "
            print(f"  {marker} {rel_path}")
        return

    # íŒ¨í‚¹ ì‹¤í–‰
    output = packer.pack()

    # ê²°ê³¼ ë¦¬í¬íŠ¸
    report = packer.get_report(output)
    print(report)

    # íŒŒì¼ ì €ì¥
    output_path = root_dir / args.output
    output_path.write_text(output, encoding='utf-8')
    print(f"ğŸ’¾ ì €ì¥ë¨: {output_path}")

    # í´ë¦½ë³´ë“œ ë³µì‚¬
    if not args.no_clipboard:
        if copy_to_clipboard(output):
            print("ğŸ“‹ í´ë¦½ë³´ë“œì— ë³µì‚¬ë¨!")
        else:
            print("âš ï¸  í´ë¦½ë³´ë“œ ë³µì‚¬ ì‹¤íŒ¨ (pyperclip ì„¤ì¹˜ í•„ìš”: pip install pyperclip)")

    print()


if __name__ == '__main__':
    main()
